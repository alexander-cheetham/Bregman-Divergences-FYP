
<!DOCTYPE html>
<html lang="en">
  <head>
    <script type="text/javascript" src="bregdivs.js"></script>
    <script type="text/javascript" charset="UTF-8"
 src="https://cdn.jsdelivr.net/npm/jsxgraph/distrib/jsxgraphcore.js"></script>
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/jsxgraph/distrib/jsxgraph.css" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css">
    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script>
    <!-- To automatically render math in text elements -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body);"></script>
        <script src="all.min.js"></script>
    <script src="statistics.min.js" type="text/javascript"></script>
    <link rel="icon" type="image/png" href="alex-assets/mlu_robot.png" />
    <link rel="stylesheet" href="alex-assets/styles/normalize.css" />
    <link rel="stylesheet" href="alex-assets/styles/font.css" />
    <link rel="stylesheet" href="alex-assets/styles/katex.css" />
    <link rel="stylesheet" href="alex-assets/styles/global.css" />
    <link rel="stylesheet" href="alex-assets/bundle.css" />
    <link rel="stylesheet" href='success.css'>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjs/11.5.0/math.js"></script>
     <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.7/dist/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
<!-- <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.9/d3.min.js"></script> -->
<script type="text/javascript" src="https://d3js.org/d3.v3.min.js"></script>
<script type="text/javascript" src="https://labratrevenge.com/d3-tip/javascripts/d3.tip.v0.6.3.js"></script>
<link type="text/css" rel="stylesheet" href="kmeans.css">
<style>


  .jumbotron
    {
      /*background-color: white;*/
      /*margin-bottom: 40px;*/
      margin-top: 20px;
      padding-bottom: 20px;
      padding-top: 5px;
    }

    #chart
    {
      background-color: #F5F2EB;
      border: 1px solid black;
    }


</style>
<!--<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-GLhlTQ8iRABdZLl6O3oVMWSktQOp6b7In1Zl3/Jr59b6EGGoI1aFkw7cmDA6j6gD" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js" integrity="sha384-w76AqPfDkMBDXo30jS1Sgez6pr3x5MlQ1ZAGC+nuZB+EYdgRZgiwxhTBTkF7CXvN" crossorigin="anonymous"></script>
-->
    <!--<script defer src="alex-assets/bundle.js"></script> this does loads -->

    <!-- meta tags -->
    <title>Bregman Divergences</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta
      name="description"
      content="A visual, interactive explanation of Bregman Divergences."
    />
    <meta name="author" content="Alexander Cheetham" />
    <!-- <meta
      name="news_keywords"
      content="linear regression classification threshold binary visual machine learning mean squared error r-squared gradient descent closed form least squares interpretability multivariate"
    />
    -->
    <meta property="og:title" content="Bregman Divergences" />

    <meta property="og:type" content="article" />
    <meta property="og:locale" content="en_US" />

    <meta property="og:image:type" content="image/jpg" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="600" />
    <script src="https://d3js.org/d3.v7.min.js"></script>
  </head>

<body>
  <section id="intro" style=' width: 70%; margin: auto;text-align: center' >
      <h1 id="intro-hed">Bregman Divergences</h1>
      <h2 id="intro-sub" style='font-family: "Amazon Ember Mono"'>A Visual Introduction to Bregman Divergences</h2>
      <h3 id="intro__date"  style='font-family: "Amazon Ember Mono"'><a >Alexander Cheetham</a>, September 2022</h3>
</section>

<br>
<section class='panel'>
<h2 class="body-header">Introduction</h2>
<p style='width:70%;margin:auto;'>
Bregman divergences are a widely used mathematical concept in machine learning that are more commonly discussed
 in academic papers, but can be challenging to understand for those encountering them for the first time.
  These divergences are significant because of their usefulness in many areas of machine learning such as
  clustering and matrix approximations.
   However, the formalism-heavy Wikipedia page on Bregman divergences may not be the most accessible
    resource for beginners. With this in mind, this page aims to provide a comprehensive and easy-to-understand
     introduction to Bregman divergences. It will cover their definition, derivation, and useful properties,
      while also discussing the role they play in machine learning. Additionally, interactive graphs will be
       provided to enhance understanding.
</p>
<div id='bibl'>
</div>
</section>
<section class='panel'>
<h2 class="body-header">History</h2>
<p class="body-text">
The Bregman divergence first appeared in a paper on solutions to convex
programming problems.
<br>
<img src="./alex-assets/images/paper-title.png" alt="Bregman Paper">
<br>
Appearing first in the section below.
<br>
<br>
<img src="./alex-assets/images/Definition.png" alt="Bregman Paper">
<br>
The definition of a Bregman divergence (retrospectively named such) was defined
in equation (1.4) as a result of trying a function that satisfied the
conditions below.
<br>
<br>
<img src="./alex-assets/images/Conditions1.png" alt="Bregman Paper">
<img src="./alex-assets/images/Conditions2.png" alt="Bregman Paper">
<br>
We will go deeper into some of these properties later in the article.
</p>
</section>
<section class='panel'>
<h2 class="body-header">Motivation and Derivation</h2>
<p class='body-text'>
The motivation for studying Bregman divergences comes from the idea of trying to
generalise the definition of squared Euclidean distance to a larger class of
distances that share the same properties. Alongside this, as we will see later
Bregman divergences have strong ties to applications in probability, machine
learning and clustering.
<br>
<br>
With this motivation in mind we will first generalise the
squared Euclidean distance(SED) between two points to a Bregman Divergence. Given two
points \( x,y \in \, \mathbb{R}^n \) the SED is:
$$d^2(x,y):=\sum_{i=1}^{n} (x_i - y_i)^2 $$
We can rewrite the definition of the
SED in terms of the inner product (\( \langle x,y \rangle = \sum_{i=1}^{d} x_iy_i  \) ).
$$d^2(x,y):=\sum_{i=1}^{n} (x_i - y_i)^2 = \langle x-y,x-y \rangle $$
Then after some manipulation we get.
$$d^2(x,y) =  \langle x-y,x-y \rangle = \mid\mid x \mid\mid^2 -
 \mid\mid y \mid\mid^2 - \langle 2y,x-y \rangle $$

 <button class="btn btn-outline-primary" type="button" data-toggle="collapse" data-target="#proof1" aria-expanded="false" aria-controls="collapseExample">
    Explanation
  </button>
  </p>
  <div class="collapse" id="proof1">
  <div class="card card-body body-text">
    <p style='overflow-x: scroll' class='body-text'>
      $$\langle x-y,x-y \rangle=||x||^2 + ||y||^2 + ||2yx||$$
      $$||x||^2 + ||y||^2 + ||2yx|| = ||x||^2 - ||y||^2 + ||2y^2||+ ||2yx||$$
      $$||x||^2 - ||y||^2 + ||2y^2||+ ||2yx||=||x||^2- ||y||^2 - (||2y^2||- ||2yx||)$$
      $$\langle 2y,x-y \rangle = |2y^2||- ||2yx||$$
      $$||x||^2- ||y||^2 - (||2y^2||- ||2yx||)=||x||^2- ||y||^2 - \langle 2y,x-y \rangle$$
  </p>
  </div>
</div>
<p class="body-text">
And after noticing that \( \frac{d}{dy}||y^2|| = 2y \) we can now rewrite the
equation in terms of the derivative of a function namely \( f(x)=x^2\)
$$d^2(x,y) = f(x) - (f(y) + \langle\nabla f(y),x-y\rangle) $$
<br>
After comparing to bregman's paper below we see that the definitions do indeed
match and therefore SED is a bregman divergence!
<br>
<img src="./alex-assets/images/Definition.png" alt="Bregman Paper">
<br>
This also lends itself to a particularly nice geometrical interpretation if we
realise that \( f(y) + \langle\nabla f(y),x-y\rangle \) is the tangent line of f
at y.
<br>
<br>
<div id="box" class="jxgbox" style="width:70%; height:60vh; margin: auto;"></div>
<script type="text/javascript">


 var board = JXG.JSXGraph.initBoard('box', {boundingbox: [-10, 10, 12, -4]});
 board.options.text.cssStyle = 'font-family: "Amazon Ember Mono"'
 var xaxis = board.create('axis', [[0.0, 0.0], [0.0, 1]]);
 var yaxis = board.create('axis', [[0.0, 0.0], [1.0, 0]]);

 theSlider = board.create('slider',[[-9,8],[-4,8],[0,0.1,1]],
  {snapWidth:0.05});
  board.create('text',[-9,8.5,
   function(){

     return 'f(x) = '+Math.round(theSlider.Value()* 100) / 100+'x^2';
   }], {fontSize: 15,})
 theFct = board.create('functiongraph',
   [function(x){return theSlider.Value()*x*x;}],{strokeColor:'#000',strokeWidth:2, highlight: false});
 yGlider = board.create('glider',[theFct],{name:'y', highlight: false,strokeColor:'#013081',fillColor:'#013081'});
 yGlider.moveTo([1.68,0.56])
 board.create('tangent', [yGlider], {strokeColor:'#FF9900',strokeWidth:2, highlight: false});
 xGlider = board.create('glider',[theFct],{name:'x', highlight: false,strokeColor:'#013081',fillColor:'#013081'});
 xGlider.moveTo([5.83,6.79])



 c = yGlider.Y()-2*theSlider.Value()*yGlider.X()**2
 yout = 2*theSlider.Value()*yGlider.X()*xGlider.X()+c
 jl = board.create('segment',[xGlider,[xGlider.X(),yout]],{strokeColor:'#013081',strokeWidth:3, highlight: false});

 board.create('text',[1,8,
  function(){
    var distance = Math.round((xGlider.Y()-yout)**2* 100) / 100
    return '||x-y||^2 = '+distance;
  }], {fontSize: 15,},position='u')
 xGlider.on('up', function(e){
    c = yGlider.Y()-2*theSlider.Value()*yGlider.X()**2
    yout = 2*theSlider.Value()*yGlider.X()*xGlider.X()+c
    board.removeObject(jl);
    board.update()
    jl = board.create('segment',[xGlider,[xGlider.X(),yout]],{strokeColor:'#013081',strokeWidth:3, highlight: false});
});
yGlider.on('up', function(f){
  board.removeObject(jl);
  c = yGlider.Y()-2*theSlider.Value()*yGlider.X()**2
  yout = 2*theSlider.Value()*yGlider.X()*xGlider.X()+c
  jl= board.create('segment',[xGlider,[xGlider.X(),yout]],{strokeColor:'#013081',strokeWidth:3, highlight: false});
  board.update()
});

theSlider.on('down', function(h){
   board.removeObject(jl);
});



</script>
<br>
<br>
</p>
<p style='overflow-x: scroll' class='body-text'>
  Handily, if we state explicitly that our distance measure must be non-negative
  we can redefine our distance measure as
  $$D_{\mathbb{f}}(x||y):=d^2(x,y) = f(x) - (f(y) + \langle\nabla f(y),x-y\rangle) \geq 0$$
  This tells us that function must lie above the tangent line for all \(x,y\)
  and gives the following inequality.
  $$f(x) \geq f(y) + \langle\nabla f(y),x-y\rangle $$
  Which is precisely the definition, assuming the function is appropriately
  differentiable, the definition of a convex function.
  <br>
  <br>
<span class="bold">Exploration of the formal definition</span>
The complete definition of a bregman divergence is presented below
<br>
  <span style='font-size: 30px; color: var(--smile);'>·</span>let F : \( \Omega
  \rightarrow \mathbb{R} \) is <color style='color: var(--smile);weight: Bold;'>continuously differentiable</color> &
 <color style='color: var(--smile);weight: Bold;'>strictly convex</color> function on the <color style='color: var(--smile);weight: Bold;'>convex set</color> \(\Omega\) with two n-dimensional
 points \(x,y \in \Omega\)<br>

 <span style='font-size: 30px; color: var(--smile);'>·</span>
  \( F(x) - (F(y) + \langle\nabla F(y),x-y\rangle) \)<br>
  <span style='font-size: 30px; color: var(--smile);'>·</span>The difference
   between the function evaluated at x and the first order Taylor approximation
   of F around y evaluated at x<br>

<br>
</p>
<p >
<nav style='width:80%;margin:auto;'>
  <div class="nav nav-tabs" id="nav-tab" role="tablist">
    <a  style='color: #000'class="nav-item nav-link body-text" id="nav-convex-tab" data-toggle="tab"
    href="#nav-profile" role="tab" aria-controls="nav-contact" aria-selected="false">Convex Set</a>
    <a style='color: #000' class="nav-item nav-link  body-text" id="nav-contdiff-tab" data-toggle="tab"
    href="#nav-home" role="tab" aria-controls="nav-home" aria-selected="false">
  Continuously Differentiable</a>
    <a style='color: #000' class="nav-item active nav-link body-text" id="nav-strcon-tab" data-toggle="tab"
    href="#nav-contact" role="tab" aria-controls="nav-profile" aria-selected="false">Strictly Convex</a>

  </div>
</nav>
<div class="tab-content card body-text" id="nav-tabContent" style='width:100%;margin:auto;'>
  <div class="tab-pane fade " id="nav-home" role="tabpanel" aria-labelledby="nav-contdiff-tab">
    A function \(\mathbb{f}\) is said to be continuously differentiable if its derivative
 exists and is itself a continuous function.
</div>
  <div class="tab-pane fade" id="nav-profile" role="tabpanel" aria-labelledby="nav-strcon-tab">
    A function such that any straight
    line between any pair of points
    on the curve is above the curve excluding the intersection of the line and the
    curve.
  </div>

  <div class="tab-pane fade show active" id="nav-contact" role="tabpanel" aria-labelledby="nav-convex-tab">
    The definition of strict convexity is a function such that any straight
    line between any pair of points
    on the curve is above the curve including the intersection of the line and the
    curve.
    </div>
</div>
</p>


<br>
</section>
<div style='width:70%;margin:auto;'>
<h2 class="body-header">Properties of Bregman Divergences: </h2>
<p class='body-text'>
Below we will explore some of the key mathematical properties of Bregman divergences
making them a useful generalisation of many existing loss/distance functions.
We note the definition of a Bregman Divergence, from before, as: Let \( \mathbb{f}:
\mathcal{S} \rightarrow \mathbb{R} \) be a strictly convex, differentiable function
defined on a convex set \( \mathcal{S} = dom(f) \subseteq \mathbb{R}^d \) and let
\( d_{f}: \mathcal{S} \; \times \; ri(\mathcal{s}) \rightarrow [0, \infty ] \) be
its corresponding bregman divergence i.e \( d_{f}(x||y) = f(x) - f(y) = \langle
 \nabla f(y), x-y \rangle \).
\[\]
</p>
<br>

<div class="accordion" id="accordionExample">
  <div class="card">
    <div class="card-header" id="headingOne">
      <h2 class="mb-0">
        <button class="btn btn-link body-header" type="button" data-toggle="collapse" data-target="#collapseOne" aria-expanded="tfa" aria-controls="collapseOne">
          Non-Negativity
        </button>
      </h2>
    </div>

    <div id="collapseOne" class="collapse" aria-labelledby="headingOne" data-parent="#accordionExample">
      <div style='overflow-x: scroll' class="card-body body-text">
        The non-negativity property; defined as \[d_{f}(x||y) \geq 0, \forall x \in
        \mathcal{s}, \forall y \in ri(\mathcal{s}). \]  is useful because
        it ensures that the distance between any two points is always greater zero or
        equal to zero when the values are the same. It is useful because it transforms
        the bregman divergence into a 'distance-like' measure rather than just a dissimilarity measure.
        In particular it can be used to create regularisation terms that penalise 'distance'
        of a solution from a reference point/distribution or enforce structure on your solution. It also allows Bregman Divergences
        to provide a notion of convergence for a sequence of points \( x_k \).
        The sequence of divergences \( d_f(x_k,x) \rightarrow 0 \) implying x
         that x is a minimizer of the objective function associated with \( \mathbb{f} \).
         See "Mirror descent and nonlinear projected subgradient methods for convex optimization" by Beck, A. and Teboulle, M., 2003. ,
         for proving convergence of a gradient descent based algorithm.
      </div>
    </div>
  </div>
  <div class="card">
    <div class="card-header" id="headingTwo">
      <h2 class="mb-0">
        <button class="btn btn-link collapsed body-header" type="button" data-toggle="collapse" data-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
          Linearity
        </button>
      </h2>
    </div>
    <div id="collapseTwo" class="collapse" aria-labelledby="headingTwo" data-parent="#accordionExample">
      <div style='overflow-x: scroll' class="card-body body-text">
        Bregman Divergences are linear operators, i.e \( \forall x \in  \mathbb{s},
        \forall y \in ri(\mathcal{s}) \; \&  \;\alpha \in \mathbb{R} \)
        \[
        d_{f_{1}+f_{2}}(x||y)=d_{f_{1}}(x||y)+d_{f_{2}}(x||y), \newline
        d_{\alpha f}(x||y) = \alpha d_{f}(x||y).
        \]
        This is a useful property because it allows optimisation problems that involve
        linear constraints or linear objective functions to be solved using optimization
        frameworks that leverage the convexity and linearity of Bregman divergences
        for its convergence and efficiency.
      </div>
    </div>
  </div>
  <div class="card">
    <div class="card-header" id="headingThree">
      <h2 class="mb-0">
        <button class="btn btn-link collapsed body-header" type="button" data-toggle="collapse" data-target="#collapseThree" aria-expanded="false" aria-controls="collapseThree">
          Equivalence Classes
        </button>
      </h2>
    </div>
    <div id="collapseThree" class="collapse" aria-labelledby="headingThree" data-parent="#accordionExample">
      <div style='overflow-x: scroll' class="card-body body-text">
        Bregman Divergences have the desirable property that generator functions differing
        only in affine terms (\( f(x) = \mathrm{A}x + b \)) i.e, \(f(x)=f_{0}(x)+\langle
        b,x \rangle + c, \; b \in \mathbb{R}^d \; \& \; c \in \mathbb{R} \) and then
        \[d_f(x||y) = d_{f_{0}}(x||y), \; \forall x \in  \mathbb{s},
        \forall y \in ri(\mathcal{s})
        \] then the set of all bregman divergences can be broken down  into Equivalence
        classes of the form:
        \[
        [f_0] = \{f \,| \, d_{f}(x||y)=d_{f_0}(x||y), \;  \forall x \in  \mathbb{s},
        \forall y \in ri(\mathcal{s}\}.
        \]
        This is a useful property because by partitioning the set of strictly convex,
        differentiable functions into equivalence classes based on their bregman divergences
        we can simplify many optimisation problems by only considering one divergence from each class.

      </div>
    </div>
  </div>
  <div class="card">
    <div class="card-header" id="headingFour">
      <h2 class="mb-0">
        <button class="btn btn-link collapsed body-header" type="button" data-toggle="collapse" data-target="#collapseFour" aria-expanded="false" aria-controls="collapseFour">
          Linear Separation
        </button>
      </h2>
    </div>
    <div id="collapseFour" class="collapse" aria-labelledby="headingFour" data-parent="#accordionExample">
      <div class="card-body body-text">
        Bregman Divergences can guarantee the existence of linear separators, because
        the the locus of points equidistant from two fixed points under a bregman
        divergence is a hyperplane i.e,
        \[
        d_f(x||\mu_1)=d_f(x||\mu_2)
        \]
        The linear separation property is useful because it enables the use of efficient
         optimization algorithms, such as support vector machines (SVMs), which rely
          on the existence of linear separators. SVMs are a popular machine learning
          technique that can be used for binary classification tasks, where the goal
           is to separate two classes of data points using a hyperplane.
      </div>
    </div>
  </div>
  <!--
  <div class="card">
    <div class="card-header" id="headingFive">
      <h2 class="mb-0">
        <button class="btn btn-link collapsed body-header" type="button" data-toggle="collapse" data-target="#collapseFive" aria-expanded="false" aria-controls="collapseFive">
          Relation to KL Divergence
        </button>
      </h2>
    </div>
    <div id="collapseFive" class="collapse" aria-labelledby="headingFive" data-parent="#accordionExample">
      <div class="card-body body-text">
        Bregman Divergences can guarantee the existence of linear separators, because
        the the locus of points equidistant from two fixed points under a bregman
        divergence is a hyperplane i.e,
        \[
        d_f(x||\mu_1)=d_f(x||\mu_2)
        \]
        The linear separation property is useful because it enables the use of efficient
         optimization algorithms, such as support vector machines (SVMs), which rely
          on the existence of linear separators. SVMs are a popular machine learning
          technique that can be used for binary classification tasks, where the goal
           is to separate two classes of data points using a hyperplane.
      </div>
    </div>
  </div>
  <div class="card">
    <div class="card-header" id="headingSix">
      <h2 class="mb-0">
        <button class="btn btn-link collapsed body-header" type="button" data-toggle="collapse" data-target="#collapseSix" aria-expanded="false" aria-controls="collapseSix">
          Generalised Pythagorean Theorem
        </button>
      </h2>
    </div>
    <div id="collapseSix" class="collapse" aria-labelledby="headingSix" data-parent="#accordionExample">
      <div class="card-body body-text">
        Bregman Divergences can guarantee the existence of linear separators, because
        the the locus of points equidistant from two fixed points under a bregman
        divergence is a hyperplane i.e,
        \[
        d_f(x||\mu_1)=d_f(x||\mu_2)
        \]
        The linear separation property is useful because it enables the use of efficient
         optimization algorithms, such as support vector machines (SVMs), which rely
          on the existence of linear separators. SVMs are a popular machine learning
          technique that can be used for binary classification tasks, where the goal
           is to separate two classes of data points using a hyperplane.
      </div>
    </div>
  </div> -->
</div>
<section>
</section>
</div>
<section class='panel'>
<h2 class="body-header">General Bregman Divergence Plots: </h2>
<br>
<div style='width:80%;margin:auto;text-align: center'>
  <p>
    Below is a widget that will test the convexity of a function and if the function
    is of form \(f: \mathbb{R} \rightarrow \mathbb{R}\) the accompanying bregman plots will be displayed.
    For some examples of generator functions and accompanying domains <a href="#divergence-table" class="badge badge-light">click here</a>.
  </p>

<input class="btn btn-primary" onclick="reset_panels()" type="reset" value="↺ Reset">
</div>
<br>
<br>
<div id='inputeq' class='body-text' style='width:70%;margin:auto;text-align: center'>
    <p> Please enter your continuous function of class \(f:\mathbb{R}^n \rightarrow \mathbb{R}\)</p>
    <label for="lossfunc">Generator function</label>
    <input type="text" id="lossfunc">
    <p>The function must have a second derivative that exists for computational tractability</p>
    <button class="btn btn-primary" id="generate" onclick="generate()">Generate</button>
    <br>
</div>
<div id='panel2' class = 'body-text' style='margin:auto;text-align: center;
display:none;'>
<div  id="eqhead">
  Inputted Equation:
</div>
<span id="lossfuncoutput"></span>
<div id='bounds_boxes'></div>
<div style='text-align:center' id='buttoncontainer'></div>
<button class="btn btn-primary" id="generate2" onclick="generate2()">Submit</button>
</div>
<div style='width:70%;margin:auto;text-align: center;display:none;'  id=panel3>
  <div style='text-align:center;margin:auto;' id='convexity_test'></div>

  </div>
  <div style='width:90%;margin:auto;text-align: center;display:none;'  id=panel4>
    <div class="container">
      <div class="row">
        <div class="col-sm">
          Generator Function:
          <div id='generatorlatex'></div>
          <div id="generatorbox" class="jxgbox" style="width:100%; height:50vh; margin: auto;"></div>
        </div>
        <div class="col-sm">
          Bregman Divergence:
          <div id='divergencelatex'></div>
          <div id="divergencebox" class="jxgbox" style="width:100%; height:50vh; margin: auto;"></div>
        </div>
      </div>
    </div>

    </div>

<script>
    var inputeq = document.getElementById('inputeq');
    var panel2 = document.getElementById('panel2');
    var output = document.getElementById('lossfuncoutput');
    var input = document.getElementById('lossfunc');
    var container = document.getElementById('buttoncontainer');
    var var_error = document.getElementById('variable_error')
    var bounds = document.getElementById('bounds_boxes')
    var convexity_div = document.getElementById('convexity_test')

    function linspace(start, stop,dt, endpoint = true) {
        const step = dt;
        const num = (1/dt)*((stop -start)  )+1
        return Array.from({length: num}, (_, i) => start + step * i);
    }

    const jsStruct = (...keys) => ((...v) => keys.reduce((o, k, i) => {o[k] = v[i]; return o} , {}))
    const Item = jsStruct('generator', 'bregdiv', 'bounds')
    var CommonDivs = [
        Item(nerdamer('x*x'), getBregDiv(nerdamer('x*x')),[-4,4,0.081]),
        Item(nerdamer('x*log(x)-x'), getBregDiv(nerdamer('x*log(x)-x')),[0,10,0.01]),
        Item(nerdamer('e^x'), getBregDiv(nerdamer('e^x')),[-10,10,0.01]),
        Item(nerdamer('-log(x)'), getBregDiv(nerdamer('-log(x)')),[0.1,10,0.01]),
        Item(nerdamer('x*log(x)+(1-x)*log(1-x)'), getBregDiv(nerdamer('x*log(x)+(1-x)*log(1-x)')),[0.001,0.999,0.01]),
        Item(nerdamer('log(1+e^x)'), getBregDiv(nerdamer('log(1+e^x)')),[-10,10,0.01]),
        Item(nerdamer('-1*(1-x*x)^(1/2)'), getBregDiv(nerdamer('-1*(1-x*x)^(1/2)')),[-1,1,0.01]),

    ];
    function getBregDiv(nerdamerobj){
      original_variable = nerdamerobj.variables()[0]
      p_var = nerdamer(nerdamerobj).sub(original_variable,"p")
      q_var = nerdamer(nerdamerobj).sub(original_variable,"q")
      diff_q = nerdamer.diff(q_var,'q')
      //difference_p_q = p_var.subtract(q_var)
      innerprod = diff_q.multiply(nerdamer('p').subtract(nerdamer('q')));
      bregdiv = p_var.subtract(q_var.add(innerprod))
      return bregdiv
    }


    function generate() {
        try {
            inputted_equation = nerdamer(input.value)
            vars = nerdamer(input.value).variables()
            vars = vars.filter(onlyUnique);
            katex.render(nerdamer(input.value).toTeX(),lossfuncoutput);
            inputeq.style.display='none';
            panel2.style.display='block'
            variables = []
            vars.forEach(function(variable){
               outer = document.createElement('div')
               outer.setAttribute('class','input-group')
               innerdiv = document.createElement('div')
               innerdiv.setAttribute('class','input-group-prepend')
               text = document.createElement('span')
               text.innerHTML = 'Please enter Lower, Upper bounds for: '+variable+' ';
               text.setAttribute('class','input-group-text')
               innerdiv.appendChild(text)
               inp1 = document.createElement('input')
               inp1.setAttribute('type','number')
               inp1.setAttribute('class','form-control')
               inp1.setAttribute('id',variable+'lbound')
               inp2 = document.createElement('input')
               inp2.setAttribute('type','number')
               inp2.setAttribute('class','form-control')
               inp2.setAttribute('id',variable+'ubound')
               //inp3 = document.createElement('input')
               //inp3.setAttribute('type','number')
               //inp3.setAttribute('class','form-control')
               //inp3.setAttribute('id','stepsize')
               outer.appendChild(innerdiv)
               outer.appendChild(inp1)
               outer.appendChild(inp2)
               //outer.appendChild(inp3)
               bounds.appendChild(outer)
               variables.push(variable)
           });

        } catch (e) {
            alert(e.message);
        }
    }
    function generate2(){
      panel2.style.display = 'none';
      panel3 = document.getElementById('panel3');
      panel3.style.display = 'block';
      var inputs = panel2.querySelectorAll("input");
      bounds=[]
      bounds_copy=[]
      inputs.forEach(function(k){
        bounds.push(parseFloat(k.value))
        bounds_copy.push(parseFloat(k.value))
      })
      stepsizes = []
      var i = Math.floor(bounds.length / 2);
      for (let j=0;j<=(i-1);j++){
        stepsizes.push((bounds[2*j+1] -  bounds[2*j]) / (100 - 1))
      }
      if(isConvex(inputted_equation,bounds,variables)==true){
        writing = document.createElement('div')
        katex.render(nerdamer(input.value).toTeX(),writing);
        morewriting = document.createElement('p')
        morewriting.innerHTML = 'Congratulations your function: '
        lastwriting = document.createElement('p')
        lastwriting.innerHTML = 'Is strictly convex'
        convexity_div.appendChild(morewriting)
        convexity_div.appendChild(writing)
        convexity_div.appendChild(lastwriting)

        if(nerdamer(input.value).variables().length==1){
          button = document.createElement('button')
          button.classList.add("btn","btn-primary")
          button.setAttribute('id','generate3')
          original_variable = nerdamer(input.value).variables()[0]
          p_var = nerdamer(input.value).sub(original_variable,"p")
          q_var = nerdamer(input.value).sub(original_variable,"q")
          diff_q = nerdamer.diff(q_var,'q')
          //difference_p_q = p_var.subtract(q_var)
          innerprod = diff_q.multiply(nerdamer('p').subtract(nerdamer('q')));
          bregdiv = p_var.subtract(q_var.add(innerprod))
          plot_data = {
            generator: nerdamer(input.value).sub(original_variable,"x"),
            bregdiv: bregdiv,
            bounds: [bounds[0],bounds[1],stepsizes[0]]
          }
          button.onclick = plot_user_breg(plot_data)
          button.innerHTML = 'Plot.'
          convexity_div.appendChild(button)
        }

      } else{
        writing = document.createElement('div')
        katex.render(nerdamer(input.value).toTeX(),writing);
        morewriting = document.createElement('p')
        morewriting.innerHTML = 'Unfortunately your function: '
        lastwriting = document.createElement('p')
        lastwriting.innerHTML = 'Is not strictly convex'
        convexity_div.appendChild(morewriting)
        convexity_div.appendChild(writing)
        convexity_div.appendChild(lastwriting)
      }

    }



  function minima_over_range(f,range,div=null){
    linspace_var = linspace(range[0],range[1],range[2])
    if (div==null){
      minima = f(range[0])
      for (var i=0;i<linspace_var.length;i+=1){
        minima = Math.min(minima,f(linspace_var[i]))
      }
      return minima
    } else{
      minima = f(range[0],div)
      for (var i=0;i<linspace_var.length;i+=1){
        minima = Math.min(minima,f(linspace_var[i],div))
      }
      return minima
    }

  }

  function plot_user_breg(data){
    if(data.bounds[0]==0){
      data.bounds[0]=data.bounds[0]+data.bounds[2]
    }
    if(data.bounds[1]==0){
      data.bounds[1]=data.bounds[1]+data.bounds[2]
    }
    nerdamer.clearVars()
    panel3.style.display = 'none';
    generator_string = "\\mathbb{f(x)}=".concat(data.generator.toTeX())
    katex.render(generator_string,document.getElementById('generatorlatex'))
    generator_f = data.generator.buildFunction()
    top_left= Math.max(generator_f(data.bounds[0]),generator_f(data.bounds[1]))
    bottom_right = minima_over_range(generator_f,data.bounds)
    bounds_diff = data.bounds[1]-data.bounds[0]
    y_diff = Math.abs(top_left - bottom_right)
    var generatorboard = JXG.JSXGraph.initBoard('generatorbox', {boundingbox:[data.bounds[0]-0.3*bounds_diff,top_left+0.3*y_diff+0.5,data.bounds[1]+0.3*bounds_diff,bottom_right-(0.3*y_diff+0.5)], axis:true, showNavigation:false});
    generatorboard.options.text.cssStyle = 'font-family: "Amazon Ember Mono"'
    generator = generatorboard.create('functiongraph', [function(x){ return generator_f(x); },data.bounds[0], data.bounds[1]],{strokeColor:'#000',strokeWidth:2, highlight: false});
    //fix_generator = generatorboard.create('slider',[[bounds[0]+Math.abs(0.3*bounds[0]+5),top_left-0.3*top_left],[bounds[1]-Math.abs(0.3*bounds[1]+5),top_left-0.3*top_left],[0,0.7,1]],{snapWidth:0.05,label:{autoPosition: true, offset:[100, 100]}});
    //fix_generator = generatorboard.create('glider',[generator],{name:'x', highlight: false,strokeColor:'#013081',fillColor:'#013081'});
    fix_generator = generatorboard.create('slider',
    [[data.bounds[0],0.75*(top_left+0.3*y_diff+0.5)],
    [data.bounds[1],0.75*(top_left+0.3*y_diff+0.5)],[data.bounds[0],(data.bounds[0]+data.bounds[1])/2,data.bounds[1]]],
    {
      label: {fontSize: 18, strokeColor: 'black'},
              name: 'xyz',
               visible: true,
              suffixLabel: 'x = ',
    }
    );
    generator_fixed_point = generatorboard.create('glider', [fix_generator.Value(), generator_f(fix_generator.Value()),generator],{ highlight: false,name:'x',label:{autoPosition: true, offset:[-10, 10]}});
    generator_fixed_point.setAttribute({ fixed: true });
    generator_tangent = generatorboard.create('tangent', [generator_fixed_point], {strokeColor:'#FF9900',strokeWidth:2, highlight: false});
    generator_val = fix_generator.Value()
    fix_generator.on('up', function(i){
      generator_val = fix_generator.Value()
      generatorboard.removeObject(generator_fixed_point)
      generatorboard.removeObject(generator_tangent)
      generatorboard.removeObject(generator_breg_dist_seg)
      generator_fixed_point = generatorboard.create('glider', [fix_generator.Value(), generator_f(fix_generator.Value()),generator],{ highlight: false,name:'x',label:{autoPosition: true, offset:[-10, 10]}});
      generator_fixed_point.setAttribute({ fixed: true });
      generator_tangent = generatorboard.create('tangent', [generator_fixed_point], {strokeColor:'#FF9900',strokeWidth:2, highlight: false});
      generator_breg_dist_seg = generatorboard.create('segment',[generator_fixed_y,[generator_fixed_y.X(),generator_fixed_y.Y()-divergence_f(generator_fixed_y.X(),generator_val)]],{strokeColor:'#013081',strokeWidth:3, highlight: false,label:{autoPosition: true, offset:[10, 10]}});
      divergenceboard.removeObject(divergence);
      divergenceboard.removeObject(divergence_fixed_point);
      divergence_fixed_point = divergenceboard.create('point', [fix_generator.Value(), 0],{ highlight: false,name:'x',label:{autoPosition: true, offset:[-10, 10]}});
      divergence = divergenceboard.create('functiongraph', [function(x){ return divergence_f(generator_val,x); },data.bounds[0], data.bounds[1]],{strokeColor:'#000',strokeWidth:2, highlight: false});
      free_glider = divergenceboard.create('glider',[fix_free.Value(),divergence_f(generator_val,fix_free.Value()),divergence],{name:'y', highlight: false,strokeColor:'#013081',fillColor:'#013081',label:{autoPosition: true, offset:[10, 10]}});
      free_eval = divergence_f(free_glider.X(),generator_val)
      breg_dist_seg = divergenceboard.create('segment',[free_glider,[free_glider.X(),0]],{strokeColor:'#013081',strokeWidth:3, highlight: false,label:{autoPosition: true, offset:[10, 10]}});
      breg_dist_seg.setLabel('D(x||y)= '+Math.round(free_eval*100)/100)

      free_glider.on('up', function(i){
        free_eval = divergence_f(free_glider.X(),generator_val)
        divergenceboard.removeObject(breg_dist_seg);
        breg_dist_seg = divergenceboard.create('segment',[free_glider,[free_glider.X(),0]],{strokeColor:'#013081',strokeWidth:3, highlight: false,label:{autoPosition: true, offset:[10, 10]}});
        breg_dist_seg.setLabel('D(x||y)= '+Math.round(free_eval*100)/100)
        divergenceboard.update()
      });
      divergenceboard.update()
    });
    generatorboard.fullUpdate()

    divergence_string = "d_{\\mathbb{f}}(x,y)=".concat(nerdamer.simplify(data.bregdiv.sub('p','x').sub('q','y').toString()).toTeX())
    katex.render(divergence_string,document.getElementById('divergencelatex'))
    //nerdamer.setVar('p',0.7)
    divergence_f = data.bregdiv.buildFunction()
    top_left= Math.max(divergence_f(data.bounds[0],generator_val),divergence_f(data.bounds[1],generator_val))
    bottom_right = minima_over_range(divergence_f,data.bounds,generator_val)
    bounds_diff = data.bounds[1]-data.bounds[0]
    y_diff = Math.abs(top_left - bottom_right)
    var divergenceboard = JXG.JSXGraph.initBoard('divergencebox', {boundingbox:[data.bounds[0]-0.3*bounds_diff,top_left+0.3*y_diff,data.bounds[1]+0.3*bounds_diff,bottom_right-0.3*y_diff], axis:true, showNavigation:false});
    divergenceboard.options.text.cssStyle = 'font-family: "Amazon Ember Mono"'
    fix_free = divergenceboard.create('slider',
    [[data.bounds[0],0.75*(top_left+0.3*y_diff)],
    [data.bounds[1],0.75*(top_left+0.3*y_diff)],[data.bounds[0],3*(data.bounds[0]+data.bounds[1])/4,data.bounds[1]]],
    {
      label: {fontSize: 18, strokeColor: 'black'},
              name: 'xyz',
               visible: true,
              suffixLabel: 'y = ',
    }
    );
    divergence = divergenceboard.create('functiongraph', [function(x){ return divergence_f(x,generator_val); },data.bounds[0], data.bounds[1]],{strokeColor:'#000',strokeWidth:2, highlight: false});
    free_glider = divergenceboard.create('glider',[fix_free.Value(),divergence_f(fix_free.Value(),generator_val),divergence],{name:'y', highlight: false,strokeColor:'#013081',fillColor:'#013081',label:{autoPosition: true, offset:[-10, 10]}});
    free_glider.setAttribute({ fixed: true });
    divergence_fixed_point = divergenceboard.create('point', [fix_generator.Value(), 0],{ highlight: false,name:'x',label:{autoPosition: true, offset:[-10, 10],label:{autoPosition: true, offset:[10, 10]}}});
    free_eval = divergence_f(generator_val,free_glider.X())
    breg_dist_seg = divergenceboard.create('segment',[free_glider,[free_glider.X(),0]],{strokeColor:'#013081',strokeWidth:3, highlight: false,label:{autoPosition: true, offset:[10, 10]}});
    breg_dist_seg.setLabel('D(x||y)= '+Math.round(free_eval*100)/100)
    generator_fixed_y = generatorboard.create('point', [free_glider.X(), generator_f(free_glider.X())],{ highlight: false,name:'y',fixed:true,label:{autoPosition: true, offset:[-10, 10],label:{autoPosition: true, offset:[10, 10]}}});
           generator_breg_dist_seg = generatorboard.create('segment',[generator_fixed_y,[generator_fixed_y.X(),generator_fixed_y.Y()-divergence_f(generator_fixed_y.X(),generator_val)]],{strokeColor:'#013081',strokeWidth:3, highlight: false,label:{autoPosition: true, offset:[10, 10]}});
    // generator_breg_dist_seg.setLabel('D(x||y)= '+Math.round(free_eval*100)/100)
     fix_free.on('up', function(i){
       generator_val = fix_generator.Value()
       divergenceboard.removeObject(free_glider)
       free_glider = divergenceboard.create('glider',[fix_free.Value(),divergence_f(generator_val,fix_free.Value()),divergence],{name:'y', highlight: false,strokeColor:'#013081',fillColor:'#013081'});
       free_glider.setAttribute({ fixed: true });
       generatorboard.removeObject(generator_fixed_y)
       generatorboard.removeObject(generator_breg_dist_seg)
       generator_fixed_y = generatorboard.create('point', [free_glider.X(), generator_f(free_glider.X())],{ highlight: false,name:'y',fixed:true,label:{autoPosition: true, offset:[-10, 10],label:{autoPosition: true, offset:[10, 10]}}});
       free_eval = divergence_f(free_glider.X(),generator_val)
       generator_breg_dist_seg = generatorboard.create('segment',[generator_fixed_y,[generator_fixed_y.X(),generator_fixed_y.Y()-divergence_f(generator_fixed_y.X(),generator_val)]],{strokeColor:'#013081',strokeWidth:3, highlight: false,label:{autoPosition: true, offset:[10, 10]}});
       divergenceboard.removeObject(breg_dist_seg);
       breg_dist_seg = divergenceboard.create('segment',[free_glider,[free_glider.X(),0]],{strokeColor:'#013081',strokeWidth:3, highlight: false,label:{autoPosition: true, offset:[10, 10]}});
       breg_dist_seg.setLabel('D(x||y)= '+Math.round(free_eval*100)/100)
       divergenceboard.update()
     });
    divergenceboard.fullUpdate()
    panel4 = document.getElementById('panel4');
    panel4.style.display = 'block';
  }



  function isConvex(fn, bounds,variables) {
      //function that evaluates at midpoint and compares to assess if
      // function convex over bounds

        first_diff=[]
        variables.forEach(function(k){
          first_diff.push(nerdamer.diff(fn,k))
        })
        second_diff = []
        first_diff.forEach(function(f_dif){
          variables.forEach(function(k){
            second_diff.push(nerdamer.diff(f_dif,k))
          })
        })
        linspaces = []
        var j = 0
        for (var i=0;i<variables.length;i+=1){
          linspaces.push(linspace(bounds[j],bounds[j+1],stepsizes[i]))
          j=j+2
        }
        let f = (a, b) => [].concat(...a.map(a => b.map(b => [].concat(a, b))));
        let cartesian = (a, b, ...c) => b ? cartesian(f(a, b), ...c) : a;
        points_to_eval = cartesian(...linspaces)
        for (var i=0;i<points_to_eval.length;i+=1){
            hessian = [...Array(variables.length)].map(e => Array(variables.length))
            max = variables.length
            c=0
            second_diff.forEach(function(k){
              temp_f = k.buildFunction(variables)
              if (variables.length > 1){
                hessian[Math.floor(c/max)][c%max] = temp_f(...points_to_eval[i])
              } else{
                hessian[Math.floor(c/max)][c%max] = temp_f(points_to_eval[i])
              }

              c=c+1
            })

          hessian = math.matrix(hessian)
          eigenvalues = math.eigs(hessian).values
          for (var k=0;k<eigenvalues._size;k+=1){
            if(eigenvalues._data[k] <0 || math.im(eigenvalues._data[k])!=0){
              return false;

            };
          };
        };
        return true;
    }


function reset_panels() {
      counter=0
      panel2.style.display = "none";
      inputeq.style.display = "block";
      var errs = document.getElementsByClassName('bregplotserr')
      for (var i=0;i<errs.length;i+=1){
          errs[i].style.display = 'none';
          }
      bounds = document.getElementById('bounds_boxes')
      bounds.innerHTML = ''
      panel3.style.display='none';
      document.getElementById('convexity_test').innerHTML = ''
      panel4.style.display = 'none';
      //generatorboard.removeObject(generator_f)
      //generatorboard.update()
      //divergenceboard.removeObject(divergence_f)
      //generatorboard.update()

    }

    function predefinedPlot(data) {

          inputeq.style.display = "none";
          panel2.style.display = "none";
          panel3.style.display='none';
          plot_user_breg(data);

        }

    function onlyUnique(value, index, self) {
      return self.indexOf(value) === index;
    }
</script>
<br>
<br>
<h2 class="body-header">Common Loss Functions:</h2>
<div style='width:80%;margin:auto;'>
<p class='body-text' style='width:100%'>
  Below are some commonly found bregman divergences, to see them plotted click
  on the function name of generator you want to inspect.
</p>
</div>
<div class='table-responsive-md' style='width:80%;margin:auto;'>
  <table class="table table-striped table-borderless" id='divergence-table'>
  <thead>
    <tr>
      <th scope="col">Function Name</th>
      <th scope="col">Generator \(f(x)\)</th>
      <th scope="col">Domain</th>
      <th scope="col">Divergence \(D_{f}(x||y)\)</th>
      <th scope="col">Divergence Name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row"><button type="button" class="btn btn-link" id="squared" onclick="predefinedPlot(CommonDivs[0])">Squared Norm</button></th>
      <td>\(x^2\)</td>
      <td>\(\mathbb{R}\)</td>
      <td>\((x-y)^2\)</td>
      <td>Squared Loss</td>
    </tr>
    <tr>
      <th scope="row"><button type="button" class="btn btn-link" id="squared" onclick="predefinedPlot(CommonDivs[1])">Shannon Entropy</button></th>
      <td>\(xlog(x)-x\)</td>
      <td>\([0,\infty)\)</td>
      <td>\(xlog(\frac{x}{y})-x+y\)</td>
      <td>Kullbach-Liebler Divergence</td>
    </tr>
    <tr>
      <th scope="row"><button type="button" class="btn btn-link" id="squared" onclick="predefinedPlot(CommonDivs[2])">Exponential</button></th>
      <td>\(e^x\)</td>
      <td>\(\mathbb{R}\)</td>
      <td>\(e^x-(x-y+1)*e^y\)</td>
      <td>Exponential Loss</td>
    </tr>
    <tr>
      <th scope="row"><button type="button" class="btn btn-link" id="squared" onclick="predefinedPlot(CommonDivs[3])">Burg Entropy</button></th>
      <td>\(-log(x)\)</td>
      <td>\((0,\infty)\)</td>
      <td>\(\frac{x}{y}-log(\frac{x}{y})-1\)</td>
      <td>Itakura-Saito Distance</td>
    </tr>
    <tr>
      <th scope="row"><button type="button" class="btn btn-link" id="squared" onclick="predefinedPlot(CommonDivs[4])">Bit Entropy</button></th>
      <td>\(x*log(x)-(1-x)*log(1-x)\)</td>
      <td>\([0,1]\)</td>
      <td>\(xlog(\frac{x}{y})-(1-x)log(\frac{1-x}{1-y})\)</td>
      <td>Logistic Loss</td>
    </tr>
    <tr>
      <th scope="row"><button type="button" class="btn btn-link" id="squared" onclick="predefinedPlot(CommonDivs[5])">Dual Bit Entropy</button></th>
      <td>\(log(1+e^x)\)</td>
      <td>\(\mathbb{R}\)</td>
      <td>\(xlog(x)-(1-x)log(1-x)\)</td>
      <td>Dual Logistic Loss</td>
    </tr>
    <tr>
      <th scope="row"><button type="button" class="btn btn-link" id="squared" onclick="predefinedPlot(CommonDivs[6])">Hellinger</button></th>
      <td>\(-\sqrt{1-x^2}\)</td>
      <td>\([-1,1]\)</td>
      <td>\((1-xy)(1-y^2)^{-1/2}-(1-x^2)^{1/2}\)</td>
      <td>Hellinger</td>
    </tr>
  </tbody>
</table>
</div>
<section>
  <br>
  <br>
  <h2  class="body-header">Applications of Bregman Divergences:</h2>
  <p style='padding-bottom:1%' class='body-text'>
    Bregman divergences are used to measure the dissimilarity between two probability distributions as such some examples of applications of Bregman divergences include:
<br>
<ol type='1' class='body-text'>
  <li style='padding-bottom:1%'>\( \textbf{Clustering}\): Bregman divergences can be used to define the dissimilarity between different clusters, which can then be used in algorithms such as k-means clustering.</li>
  <li style='padding-bottom:1%'>\( \textbf{Image compression}\): Bregman divergences can be used to measure the dissimilarity between an original image and a compressed version of the image, which can be used to optimize the compression algorithm.</li>
  <li style='padding-bottom:1%'>\( \textbf{Machine learning}\): Bregman divergences can be used as loss functions in machine learning algorithms, such as in the optimization of neural networks.</li>
  <li style='padding-bottom:1%'>\( \textbf{Recommender systems}\): Bregman divergences can be used to measure the dissimilarity between different users' preferences and can be used to make personalized recommendations.</li>
  <li style='padding-bottom:1%'>\( \textbf{Signal processing}\): Bregman divergences can be used in signal processing to measure the dissimilarity between a signal and a compressed version of the signal, which can be used to optimize the compression algorithm.</li>
</ol>

  </p>
  <section class='panel'>
  <h2 class="body-header">Exploring Bregman Enhanced Clustering: </h2>
  <br>
  <p class='body-text'>
    When knowledge about the underlying problem setting or distribution of data is known in advance.
    Clustering algorithms can be made shown to perform more accurately when
    utilising bregman divergences to create dissimilarity measures that model
    underlying data more accurately.<br><br>Below we will explore how K-means
    clustering can perform better on data sampled from non-normal distributions
    with adapted distance/centroid functions. A Brief Refesher on the K-means
    Algorithm is provided below.
  </p>
  <br>
  <br>
  <div class="accordion" style='width:70%;margin:auto;' id="accordion2">
    <div class="card">
      <div class="card-header" id="headingOne">
        <h2 class="mb-0">
          <button class="btn btn-link body-header" type="button" data-toggle="collapse" data-target="#collapseOne" aria-expanded="tfa" aria-controls="collapseOne">
            K-means Set-up
          </button>
        </h2>
      </div>

      <div id="collapseOne" class="collapse" aria-labelledby="headingOne" data-parent="#accordion2">
        <div style='overflow-x: scroll' class="card-body body-text">
          <ol type='I' class='body-text'>
            <li style='padding-bottom:1%'>Assume there are \( K\) groups.</li>
            <li style='padding-bottom:1%'>For each group \(k \in \{1,...,K\}\) assume a group mean \( \mathbf{\mu}_{k} \)</li>
            <li style='padding-bottom:1%'>Aim: Partition data points \( \mathbf{x}_i,...,\mathbf{x}_n \) into \(K\) non-overlapping groups</li>
            <li style='padding-bottom:1%'>Each of the \(n\) data points \(\mathbf{x}_i \) is assigned to exactly one of the \(K\) groups.</li>
            <li style='padding-bottom:1%'>Maximise the homogeneity within each group (i.e. each group should contain similar objects).</li>
            <li style='padding-bottom:1%'>Maximise the heterogeneity between the different groups (i.e each group should differ from the other groups).
          </ol>
        </div>
      </div>
    </div>
    <div class="card">
      <div class="card-header" id="headingTwo">
        <h2 class="mb-0">
          <button class="btn btn-link collapsed body-header" type="button" data-toggle="collapse" data-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
            K-means Algorithm
          </button>
        </h2>
      </div>
      <div id="collapseTwo" class="collapse" aria-labelledby="headingTwo" data-parent="#accordion2">
        <br>
        <p class='body-text'>After running K-means we will get estimates of
          \( \hat{\mu}_k\) of the group means, as well allocations
          \( y_i \in \{1,..,K\}\) of each data point \( \mathbf{x}_i \) to one of the classes.
        </p>
        <br>
        <br>
        <p class='body-text'>
          At the start of the algorithm the \(n \) observations
          \( \mathbf{x}_1,...,\mathbf{x}_n \) are randomly allocated
          with equal probability to one of the \(K \) groups. The resulting assignment is
          \(y_1,...y_n\), with each\(y_i \in \{1,..K\}\). With \( G_k=\{i|y_i=k\}\)
 we denote the set of indices of the data points in cluster
\(k\), and with \(n_k = |G_k|\) the number of samples in cluster.
        </p>
        <br>
        <br>
        <ol type='1' class='body-text'>
        <li style='padding-bottom:1%'> Estimate the group means, with a centroid
          combiner function.

        <li style='padding-bottom:1%'> Update the group allocations, with a specified
          dissimilarity measure. Specifically, assign each data point
          \(x_i\)to the group \(k\) with the nearest \(\hat{\mu}_k\).
          \[y_i=\underset{k}{\mathrm{argmin}}\;D_f(\hat{\mu}_k||x_i)\]

        </ol>
        <p class='body-text'>
          Steps 1 and 2 are repeated until the algorithm converges
          (i.e. until the group allocations don’t change any more) or until
          a specified upper limit of iterations is reached.

      </div>
    </div>
  </div>
  <br>
  <br>
  <p class='body-text'>
    Some specific examples of Centroid Combiner/dissimilarity Measure
    combinations and their respective dual exponential family probability
    distribution are shown below. The centroid combiner and associated dissimilarity
    measure can be directly plugged into the K-means algorithm.
  </p>
  <br>
  <br>
  <div class='table-responsive-md' style='width:80%;margin:auto;'>
    <table class="table table-striped table-borderless" id='divergence-table'>
    <thead>
      <tr>
        <th scope="col">Loss Function</th>
        <th scope="col">Centroid Combiner</th>
        <th scope="col">Name</th>
        <th scope="col">Dissimilarity Measure</th>
        <th scope="col">Optimal Distribution</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <th scope="row">Squared Loss</button></th>
        <td>\(\frac{1}{m}\sum^M_i q_i\)</td>
        <td>Arithmetic Mean</td>
        <td>\((x-y)^2\)</td>
        <td>Normal Distribution</td>
      </tr>
      <tr>
        <th scope="row"> Poisson Regression Loss</th>
        <td>\(\prod^M_i q_i^{\frac{1}{m}}\)</td>
        <td>Geometric Mean</td>
        <td>\(xlog(\frac{x}{y})-(x+y)\)</td>
        <td>Poisson Distribution</td>
      </tr>
      <tr>
        <th scope="row"> Itakura-Saito loss</th>
        <td>\(1/\frac{1}{m}\sum^M_i q_i\)</td>
        <td>Harmonic Mean</td>
        <td>\(\frac{x}{y}-log(\frac{x}{y})-1\)</td>
        <td>Gamma exponential family</td>
      </tr>


    </tbody>
  </table>
  </div>
  <br>
  <br>
  <script src="kmeans.js"></script>

  <script>

    // $(document).ready(function()
    // {
    //   kMeans("#kmeans", 600, 600, 1000, 3,10,1,1);
    //     //kMeans("body", 250, 250, 1000, 5, 10);
    //   });
      $(function()
        {
        $('.kmeanslider').on('input change', function(){
                  $(this).next($('.slider_label')).html(this.value);
                });
              $('.slider_label').each(function(){
                  var value = $(this).prev().attr('value');
                  $(this).html(value);
                });


        })
         async function generate_kmeans(){
          var form_container = document.getElementById('kmeansinputs');
          var kmeans_graphs = document.getElementById('kmeans_graphs');
          var numclust = document.getElementById('kmeanslider').value
          const radioButtons = document.querySelectorAll('input[name="kmeansRadios"]');
          for (const radioButton of radioButtons) {
                if (radioButton.checked) {
                    selecteddistr = radioButton.value;
                    break;
                }
            }
            form_container.style.display='none';
            kmeans_graphs.style.display='block';
            let width = 0.7*screen.width/3;
            let height = screen.height/2.5;
            if(selecteddistr=='0'){
              dword='Normal'
            } else{
              dword='Poisson'
            }
            var ktitle = document.getElementById('ktitle')
            ktitle.innerHTML='The True Distribution of the data is '+dword
            //console.log(numclust)
            var pcstart = await kMeans("#nothinghere", width, height, 500, numclust,10,selecteddistr,0);
            var pc =  await kMeans("#kmeans", width, height, 500, numclust,10,selecteddistr,0,pcstart);
            var pc2 =  await kMeans("#kmeans2", width, height, 500, numclust,10,selecteddistr,1,pcstart);
            await delay(4000);

            var true_params = pcstart.params.sort(function(a,b){return a[0] < b[0]})
            var normalcentroids=pc.c.slice(-numclust).sort(function(a,b){return a[0] < b[0]});
            var poissoncentroids=pc2.c.slice(-numclust).sort(function(a,b){return a[0] < b[0]});
            var normal_error=0;
            var poisson_error=0;
            var true_str=''
            var poisson_str='';
            var normal_str='';
            for (var i=0; i<=numclust-1;i++){
              true_str = true_str +'('+true_params[i][0]+','+true_params[i][1]+'), '
              poisson_str = poisson_str +'('+Math.round(poissoncentroids[i][0]*100)/100+','+Math.round(poissoncentroids[i][1]*100)/100+'), '
              normal_str = normal_str +'('+Math.round(normalcentroids[i][0]*100)/100+','+Math.round(normalcentroids[i][1]*100)/100+'), '
              normal_error = normal_error + Math.pow((normalcentroids[i][0]-true_params[i][0]),2)+Math.pow((normalcentroids[i][1]-true_params[i][1]),2)
              poisson_error = poisson_error + Math.pow((poissoncentroids[i][0]-true_params[i][0]),2)+Math.pow((poissoncentroids[i][1]-true_params[i][1]),2)
            }
            if(normal_error<poisson_error){
              document.getElementById("outerbox1").style.backgroundColor = "rgba(144, 238, 144, 0.5)";

            } else{
              document.getElementById("outerbox2").style.backgroundColor = "rgba(144, 238, 144, 0.5)";

            }
            document.getElementById('spinner1').style.display='none';
            document.getElementById('spinner2').style.display='none';
            document.getElementById('trueparams').innerHTML='With true cluster centers: ' + true_str
            document.getElementById('data1').innerHTML='Approximation Error: ' + Math.round(normal_error*100)/100 +'<br> Computed Centroids: ' + normal_str
            document.getElementById('data2').innerHTML='Approximation Error: ' + Math.round(poisson_error*100)/100 +'<br> Computed Centroids: ' + poisson_str


        }
        const delay = ms => new Promise(res => setTimeout(res, ms));
        function reset_kmeans() {
          var form_container = document.getElementById('kmeansinputs');
          var kmeans_graphs = document.getElementById('kmeans_graphs');
          document.getElementById('kmeans').innerHTML='';
          document.getElementById('kmeans2').innerHTML='';
          document.getElementById('data1').innerHTML='';
          document.getElementById('data2').innerHTML='';
          document.getElementById('trueparams').innerHTML='';
          document.getElementById('spinner1').style.display='block';
          document.getElementById('spinner2').style.display='block';
          document.getElementById("outerbox1").style.backgroundColor = "";
          document.getElementById("outerbox2").style.backgroundColor = "";
          document.getElementById('kmeanslider').value='3';
          document.getElementById('sliderlabel').innerHTML='3';
          form_container.style.display='block';
          kmeans_graphs.style.display='none';
        }
    </script>
    <div style='width:70%;text-align:center;margin:auto;'>
        <input class="btn btn-primary" onclick="reset_kmeans()" type="reset" value="↺ Reset">
        <br>
        <br>
        <div id='kmeansinputs'>
          <div class='form-group'>
            <label class="" for="kmeanslider">Number of Clusters: </label>
            <input  id='kmeanslider' class='kmeanslider' type="range" value="4" min="2" max="5" step="1" data-step-labels="[2, 3, 4,5]">
            <span id='sliderlabel'  class="slider_label"></span>
          </div>
          <p>True Distribution of the Data:</p>
          <div class="form-check">
            <input class="form-check-input" type="radio" name="kmeansRadios" id="poissonradio" value="1" checked>
            <label class="form-check-label" for="exampleRadios1">
              Poisson Distribution
            </label>
          </div>

          <div class="form-check">
            <input class="form-check-input" type="radio" name="kmeansRadios" id="normalradio" value="0">
            <label class="form-check-label" for="exampleRadios2">
              Normal Distribution
            </label>
          </div>
          <br>
          <button class="btn btn-primary" onclick='generate_kmeans()'>Submit</button>
        </div>

    </div>
    <div id='kmeans_graphs' class="container" style='margin:auto;display:none;text-align:center;'>
      <p id='ktitle'></p>
      <p id='trueparams'></p>
      <div class="row" style="margin-top:10px">
      <div id='outerbox1' style='margin:auto;text-align:center;padding-bottom: 2%;'class="">
        <p>K-means+Assumed Normal Distribution</p>
        <div id='spinner1'>
          <div class="spinner-border" style="width: 2rem; height: 2rem;" role="status">
            <span class="sr-only">Loading...</span>
          </div>

        </div>
        <div id='data1'></div>
        <br>
      <div id="kmeans"  class="kmeans-chart col-md-10" align="center"></div>


    </div>
      <div id='outerbox2' style='margin:auto;text-align:center;padding-bottom: 2%;'class="">
        <p>K-means+Assumed Poisson Distribution</p>
        <div id='spinner2'>
          <div class="spinner-border" style="width: 2rem; height: 2rem;" role="status">
            <span class="sr-only">Loading...</span>
          </div>
        </div>
        <div id='data2'></div>
        <br>
      <div id="kmeans2"  class="kmeans-chart col-md-10" align="center"></div>


      </div>
    </div>
      <div class="clearfix"></div>

      </div>

    </div>
</section>
<br>
<br>



</body>
